{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b141cae-aab7-412f-a673-69fa1deabfc3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d6e36e27-5289-422e-8d2d-69d375d650cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel, BartTokenizer, BartForConditionalGeneration,  BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import textwrap\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "bfa1c440-ed15-4ed7-94f2-eaaa5d31865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ae09f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "with open('articles.json', 'r', encoding='utf-8') as f:\n",
    "    articles = json.load(f)  \n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "def summarize_text(text, max_len=80):\n",
    "    inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=max_len, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bef9b106-1d22-4e13-9c09-d8980c72acfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1046007950.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[198], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"summaries.txt generated\")\"\"\"\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "summaries = [summarize_text(article['text']) for article in articles]\n",
    "\n",
    "with open(\"summaries.txt\", \"w\", encoding='utf-8') as file:\n",
    "    for summary in summaries:\n",
    "        file.write(f\"{summary}\\n\")\n",
    "\n",
    "print(\"summaries.txt generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f60c8b92-9174-421c-a105-8ad71fd9563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_article(summary_sentences, min_words=200, max_words=1000, model_name='gpt2-medium'):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    input_text = \" \".join(summary_sentences)\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_words,\n",
    "        min_length=min_words,\n",
    "        num_beams=5,  \n",
    "        no_repeat_ngram_size=2, \n",
    "        early_stopping=True,\n",
    "        temperature=0.7,  \n",
    "        top_k=50,  \n",
    "        top_p=0.95 \n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ea5b5be9-542d-4830-9c94-fe1f77844299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Donald Trump lost. But Trumpism did not. It won in the parts of the country and with the voters whom Trump catered to. Joe Biden defeated Trump to win the presidency, and is on pace to win up to 306 electoral votes. In a typical election year, such a victory would mean Biden would have carried other Democrats along with him.\n",
      "\n",
      "This is not to say that Trump's victory was a foregone conclusion. There are plenty of reasons to be skeptical of his victory, including the fact that he won the popular vote but lost the Electoral College. And there is no reason to believe that Democrats will be able to recapture the House of Representatives in 2018, which would be the first time since the Civil War that the party has won back the White House since Reconstruction. Still, it is important to remember that this election was not a referendum on Trump, or even on the Republican Party, but rather a contest between two very different visions for the future of American politics. The Democratic Party has a long way to go before it can claim to represent the interests of working people and the middle class.\n"
     ]
    }
   ],
   "source": [
    "summary_sentences = [\"President Donald Trump lost.\", \"But Trumpism did not.\",\"It won in the parts of the country and with the voters whom Trump catered to. Joe Biden defeated Trump to win the presidency, and is on pace to win up to 306 electoral votes.\",\n",
    "                     \"In a typical election year, such a victory would mean Biden would have carried other Democrats along with him.\"\n",
    "]\n",
    "\n",
    "article1 = generate_article(summary_sentences)\n",
    "print(article1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e86138fd-be10-4e02-b23f-6c98d4b7fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumana Azam was working 16-hour days responding to an influx of coronavirus patients. During the worst of it, the 34-year-old respiratory therapist was facing multiple deaths a day. Her hours have decreased since then, but another major event in Azam's life ended this year.\n",
      "\n",
      "Azam, who was born in Pakistan, was diagnosed with acute respiratory syndrome, or ARDS, when she was 4 years old. The condition is characterized by fever, cough, and shortness of breath, which can last for days or even weeks. It's caused by a virus that infects the airways, causing inflammation and inflammation of the lungs, leading to pneumonia, bronchitis, emphysema, sinusitis and even death. In the United States, more than 1,000 people die each year from the virus, according to the Centers for Disease Control and Prevention (CDC). The virus is spread through close contact with an infected person, such as coughing, sneezing or touching a sick person's face or mouth. A person can also contract the disease from another person who is infected with the same virus. People who are infected can spread the infection to others through direct contact, through sharing needles or other syringes, by sharing food or drink contaminated with infected blood or by touching infected surfaces or objects.\n"
     ]
    }
   ],
   "source": [
    "summary_sentences = [\"Jumana Azam was working 16-hour days responding to an influx of coronavirus patients.\", \n",
    "                     \"During the worst of it, the 34-year-old respiratory therapist was facing multiple deaths a day.\",\n",
    "\"Her hours have decreased since then, but another major event in Azam's life ended this year.\"]\n",
    "\n",
    "article2 = generate_article(summary_sentences)\n",
    "print(article2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e8a0eff1-8dec-4474-b770-9dd1ec64f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the children died soon after being rescued, while a fourth child was still trapped. The Friday afternoon quake that struck Turkey’s Aegean coast and north of the Greek island of Samos registered a magnitude of 6.6. It toppled buildings in Izmir and triggered a small tsunami in the Seferihisar district.\n",
      "\n",
      "Turkey's Prime Minister Ahmet Davutoğlu said the death toll was expected to rise as rescuers continued to search for survivors. \"We are trying to find as many people as we can,\" he said, according to the state-run Anadolu news agency. He added that rescue teams had found the body of a woman who had been trapped in a collapsed building, but did not say whether she was among the dead. A rescue official told Reuters that the woman was believed to be in her late 20s or early 30s and was wearing a headscarf when she fell into the rubble. She was taken to a hospital for treatment, the official said.\n"
     ]
    }
   ],
   "source": [
    "summary_sentences = [\"One of the children died soon after being rescued, while a fourth child was still trapped.\",\n",
    "                    \"The Friday afternoon quake that struck Turkey’s Aegean coast and north of the Greek island of Samos registered a magnitude of 6.6.\",\n",
    "                    \"It toppled buildings in Izmir and triggered a small tsunami in the Seferihisar district.\"]\n",
    "\n",
    "article3 = generate_article(summary_sentences)\n",
    "print(article3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "76b2475a-fce6-42bd-9ee9-3bbc375c65ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nations are scrambling to ramp up vaccination campaigns in hopes of stemming the tide of infections. Pfizer-BioNTech and Moderna vaccines, both based on new mRNA technology, have been approved for emergency use in multiple countries Other vaccines, such as the Oxford-AstraZeneca vaccine, are in the final stages of approval. distribution networks have been tested by the need to store and transport vaccines at extremely low temperatures. In many low-income countries, there are concerns about access to cold-chain infrastructure. In some countries, misinformation and distrust of governments and pharmaceutical companies have led to doubts about the safety of the vaccines. For example, the World Health Organization's Advisory Committee on Immunization Practices (ACIP) issued a report in 2010 stating that the use of cold chain vaccines in developing countries is not recommended. The ACIP also stated that there is no evidence that vaccines are safe or effective in children under the age of 6 years.\n",
      "\n",
      "In addition to vaccine safety concerns, many countries are also concerned about vaccine-preventable diseases, including measles, mumps, rubella (MMR), polio, tetanus, diphtheria, pertussis (whooping cough), hepatitis B, hepatitis C, meningococcal disease (Meningococcus), and hepatitis A (Hepatitis A). These diseases are spread through contact with contaminated water, contaminated food, and contaminated surfaces. Vaccines can be used to prevent these diseases by preventing the spread of disease-causing bacteria and viruses, as well as by protecting the body from the effects of those diseases.\n"
     ]
    }
   ],
   "source": [
    "summary_sentences = [\"Nations are scrambling to ramp up vaccination campaigns in hopes of stemming the tide of infections.\",\n",
    "                     \"Pfizer-BioNTech and Moderna vaccines, both based on new mRNA technology, have been approved for emergency use in multiple countries\",\n",
    "\"Other vaccines, such as the Oxford-AstraZeneca vaccine, are in the final stages of approval.\",\n",
    "\"distribution networks have been tested by the need to store and transport vaccines at extremely low temperatures.\",\n",
    " \"In many low-income countries, there are concerns about access to cold-chain infrastructure.\",\n",
    "                     \"In some countries, misinformation and distrust of governments and pharmaceutical companies have led to doubts about the safety of the vaccines.\"]\n",
    "\n",
    "article4 = generate_article(summary_sentences)\n",
    "print(article4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "72735479-17ac-40a5-aaef-6b71154a1ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California is enduring its worst wildfire season on record. More than 3.1 million acres have been scorched and dozens of major blazes are still active. The devastation has already claimed at least 25 lives, destroyed thousands of homes, and displaced hundreds of thousands of residents. \"This is a crisis unlike anything we’ve seen,\" said Cal Fire Chief Thom Porter.\n",
      "\n",
      "The California Department of Forestry and Fire Protection (Cal Fire) has declared a state of emergency for the entire state, as well as the San Joaquin Valley, Kern County, Sacramento, San Francisco Bay Area, Northern California, Southern California and Northern Nevada. In addition, the National Weather Service has issued a severe thunderstorm watch for much of the state and the Pacific Northwest, including Washington, Oregon, Idaho, Montana, Nevada, Colorado, Utah, Arizona, New Mexico, Texas, Oklahoma, South Dakota, Nebraska, Kansas, Illinois, Indiana, Michigan, Wisconsin, Minnesota, Iowa, Missouri, Kentucky, Tennessee, Georgia, North Carolina, Alabama, Mississippi, Arkansas, Louisiana, Florida, West Virginia, Ohio, Pennsylvania, Delaware, Maryland, Massachusetts, Rhode Island, Vermont, Virginia and New Hampshire.\n"
     ]
    }
   ],
   "source": [
    "summary_sentences = [\"California is enduring its worst wildfire season on record.\",\n",
    "                     \"More than 3.1 million acres have been scorched and dozens of major blazes are still active.\",\n",
    "\"The devastation has already claimed at least 25 lives, destroyed thousands of homes, and displaced hundreds of thousands of residents.\",\n",
    "                     \"\\\"This is a crisis unlike anything we’ve seen,\\\" said Cal Fire Chief Thom Porter.\"]\n",
    "\n",
    "article5 = generate_article(summary_sentences)\n",
    "print(article5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9dc47c43-72d0-4491-83ee-52d0b1e737e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margaret Keenan, 90, became the first person in the world to receive the Pfizer vaccine outside of clinical trials. Officials have emphasized that patience will be needed before vaccines can bring an end to the pandemic. \"This is a great Christmas present,\" Keenan says.\n",
      "\n",
      "Keenan and her husband, John, have lived in New York City for more than 40 years. They have two children, a boy and a girl, and they have never had a flu shot. But when they heard about the vaccine, they knew they had to get it for their son, who has a rare form of the flu, called H1N1, which can cause severe illness and death. The vaccine is given to children between the ages of 6 months and 12 years old, but it can also be given at any age to adults who are at high risk of contracting the disease, such as pregnant women, people with weakened immune systems, or people who have recently traveled to an area where the virus has been circulating for a prolonged period of time.\n"
     ]
    }
   ],
   "source": [
    "summary_sentences = [\"Margaret Keenan, 90, became the first person in the world to receive the Pfizer vaccine outside of clinical trials.\",\n",
    "                     \"Officials have emphasized that patience will be needed before vaccines can bring an end to the pandemic.\",\n",
    "                     \"\\\"This is a great Christmas present,\\\" Keenan says.\"]\n",
    "\n",
    "article6 = generate_article(summary_sentences)\n",
    "print(article6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "20127042-cfb2-4c1f-8a00-0becc08575b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "#gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def compute_perplexity(text, model, tokenizer, device):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "    return torch.exp(loss).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "935a38dd-3cd2-4a9e-b43d-adaa33839654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_burstiness(text, tokenizer):\n",
    "    tokenized = tokenizer.encode(text)\n",
    "    token_counts = Counter(tokenized)\n",
    "    frequencies = list(token_counts.values())\n",
    "    if len(frequencies) > 1:\n",
    "        mean_freq = np.mean(frequencies)\n",
    "        variance = np.var(frequencies)\n",
    "        burstiness_score = variance / mean_freq if mean_freq != 0 else 0\n",
    "    else:\n",
    "        burstiness_score = 0 \n",
    "    \n",
    "    return burstiness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "88e74109-055a-4337-9ba0-76ff19a96e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 12.000144004821777\n",
      "Burstiness: 2.3336466165413534\n",
      "Perplexity: 44.29035568237305\n",
      "Burstiness: 1.6412958626073382\n"
     ]
    }
   ],
   "source": [
    "perplexity = compute_perplexity(article1, gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(article1, gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")\n",
    "perplexity = compute_perplexity(articles[0]['text'], gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(articles[0]['text'], gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3e4342b6-4a7c-4ae4-ac33-e04ea3f2f03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 11.710691452026367\n",
      "Burstiness: 2.4543227856480865\n",
      "Perplexity: 43.00416564941406\n",
      "Burstiness: 1.288589599700711\n"
     ]
    }
   ],
   "source": [
    "perplexity = compute_perplexity(article2, gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(article2, gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")\n",
    "perplexity = compute_perplexity(articles[10]['text'], gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(articles[10]['text'], gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2f644236-f74b-4566-8ece-4c046f891aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 11.565011024475098\n",
      "Burstiness: 1.2923367083581494\n",
      "Perplexity: 21.6721248626709\n",
      "Burstiness: 1.0806883675623025\n"
     ]
    }
   ],
   "source": [
    "perplexity = compute_perplexity(article3, gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(article3, gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")\n",
    "perplexity = compute_perplexity(articles[20]['text'], gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(articles[20]['text'], gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f9069944-87be-4e4b-b84d-4109efc9c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 35.59250259399414\n",
      "Burstiness: 2.3445199660152927\n",
      "Perplexity: 21.9725341796875\n",
      "Burstiness: 1.614270685067145\n"
     ]
    }
   ],
   "source": [
    "perplexity = compute_perplexity(article4, gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(article4, gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")\n",
    "perplexity = compute_perplexity(articles[96]['text'], gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(articles[96]['text'], gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "bea88e7c-c2df-4640-8d2a-4e99a0758481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 10.235406875610352\n",
      "Burstiness: 9.665434173669471\n",
      "Perplexity: 13.818424224853516\n",
      "Burstiness: 1.268199233716475\n"
     ]
    }
   ],
   "source": [
    "perplexity = compute_perplexity(article5, gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(article5, gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")\n",
    "perplexity = compute_perplexity(articles[92]['text'], gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(articles[92]['text'], gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7e2982a4-9b28-4adb-9955-0b609281557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 10.209077835083008\n",
      "Burstiness: 1.7292312024781757\n",
      "Perplexity: 19.286537170410156\n",
      "Burstiness: 0.348358585858586\n"
     ]
    }
   ],
   "source": [
    "perplexity = compute_perplexity(article6, gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(article6, gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")\n",
    "perplexity = compute_perplexity(articles[99]['text'], gpt2_model, gpt2_tokenizer, device)\n",
    "burstiness = compute_burstiness(articles[99]['text'], gpt2_tokenizer)\n",
    "print(f\"Perplexity: {perplexity}\")\n",
    "print(f\"Burstiness: {burstiness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f2b19f0b-5e83-42e6-9676-4c1a34658313",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [article[\"text\"] for article in articles]\n",
    "labels = [0] * 50 + [1] * 50  # 1 = AI, 0 = Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e586b88c-c178-49e2-84cd-7878682aa028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.7108 | Val Accuracy = 0.8500\n",
      "Epoch 2: Train Loss = 0.5654 | Val Accuracy = 0.9000\n",
      "Epoch 3: Train Loss = 0.4265 | Val Accuracy = 0.9500\n",
      "Epoch 4: Train Loss = 0.3401 | Val Accuracy = 0.9500\n",
      "Epoch 5: Train Loss = 0.2299 | Val Accuracy = 0.9500\n",
      "Epoch 6: Train Loss = 0.1495 | Val Accuracy = 0.9500\n",
      "Epoch 7: Train Loss = 0.1083 | Val Accuracy = 1.0000\n",
      "Epoch 8: Train Loss = 0.0682 | Val Accuracy = 0.9500\n",
      "Epoch 9: Train Loss = 0.0496 | Val Accuracy = 0.9500\n",
      "Epoch 10: Train Loss = 0.0336 | Val Accuracy = 1.0000\n",
      "Epoch 11: Train Loss = 0.0229 | Val Accuracy = 1.0000\n",
      "Epoch 12: Train Loss = 0.0186 | Val Accuracy = 1.0000\n",
      "Epoch 13: Train Loss = 0.0161 | Val Accuracy = 1.0000\n",
      "Epoch 14: Train Loss = 0.0120 | Val Accuracy = 1.0000\n",
      "Epoch 15: Train Loss = 0.0107 | Val Accuracy = 1.0000\n",
      "Epoch 16: Train Loss = 0.0090 | Val Accuracy = 1.0000\n",
      "Epoch 17: Train Loss = 0.0077 | Val Accuracy = 1.0000\n",
      "Epoch 18: Train Loss = 0.0080 | Val Accuracy = 1.0000\n",
      "Epoch 19: Train Loss = 0.0063 | Val Accuracy = 1.0000\n",
      "Epoch 20: Train Loss = 0.0069 | Val Accuracy = 1.0000\n",
      "Epoch 21: Train Loss = 0.0052 | Val Accuracy = 1.0000\n",
      "Epoch 22: Train Loss = 0.0048 | Val Accuracy = 1.0000\n",
      "Epoch 23: Train Loss = 0.0046 | Val Accuracy = 1.0000\n",
      "Epoch 24: Train Loss = 0.0045 | Val Accuracy = 1.0000\n",
      "Epoch 25: Train Loss = 0.0043 | Val Accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "combined = list(zip(texts, labels))\n",
    "random.shuffle(combined)\n",
    "texts[:], labels[:] = zip(*combined)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].squeeze(0),\n",
    "            'attention_mask': enc['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = self.dropout(out.pooler_output)\n",
    "        return self.fc(pooled)\n",
    "\n",
    "def train_model(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "train_ds = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_ds = TextDataset(val_texts, val_labels, tokenizer)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(25):\n",
    "    train_loss = train_model(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_acc = evaluate_model(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f} | Val Accuracy = {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "baf43d7d-c4ee-4aa7-a0d7-f675c5c6aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, texts, device, max_len=128):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            enc = tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=max_len,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            input_ids = enc['input_ids'].to(device)\n",
    "            attention_mask = enc['attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            pred = torch.argmax(outputs, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "90754bb6-d0ce-4b1e-9fec-3ed3b6465129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Human] Human\n",
      "[Human] Human\n",
      "[Human] Human\n",
      "[Human] Human\n",
      "[Human] Human\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n"
     ]
    }
   ],
   "source": [
    "with open('testarticles.json', 'r', encoding='utf-8') as f:\n",
    "    testarticles = json.load(f)  \n",
    "\n",
    "test_texts = [test[\"text\"] for test in testarticles]\n",
    "truevalue = [\"Human\",\"Human\",\"Human\",\"Human\",\"Human\",\"AI\",\"AI\",\"AI\",\"AI\",\"AI\"]\n",
    "# Predict (0 = human, 1 = AI)\n",
    "i = 0\n",
    "predicted_classes = predict(model, tokenizer, test_texts, device)\n",
    "for text, pred in zip(test_texts, predicted_classes):\n",
    "    label = \"AI\" if pred == 1 else \"Human\"\n",
    "    print(f\"[{label}] {truevalue[i]}\")\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0dff6778-0293-4973-9b9f-3183311dc15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.33%\n",
      "[Human] Human (49.05767059326172)\n",
      "[AI] Human (27.24824333190918)\n",
      "[Human] Human (61.7662353515625)\n",
      "[Human] Human (50.51237487792969)\n",
      "[AI] Human (13.234869956970215)\n",
      "[AI] AI (27.44577407836914)\n",
      "[AI] AI (23.773452758789062)\n",
      "[AI] AI (29.323810577392578)\n",
      "[AI] AI (32.390220642089844)\n",
      "[AI] AI (18.873767852783203)\n"
     ]
    }
   ],
   "source": [
    "perplexities = [compute_perplexity(text, gpt2_model, gpt2_tokenizer, device) for text in texts]\n",
    "\n",
    "X = np.array(perplexities).reshape(-1, 1)  \n",
    "y = np.array(labels)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "test_texts = [test[\"text\"] for test in testarticles]\n",
    "truevalue = [\"Human\",\"Human\",\"Human\",\"Human\",\"Human\",\"AI\",\"AI\",\"AI\",\"AI\",\"AI\"]\n",
    "\n",
    "i=0\n",
    "for text in test_texts:\n",
    "    new_perplexity = compute_perplexity(text, gpt2_model, gpt2_tokenizer, device)\n",
    "    pred = classifier.predict([[new_perplexity]])[0]\n",
    "    label = \"AI\" if pred == 1 else \"Human\"\n",
    "    print(f\"[{label}] {truevalue[i]} ({new_perplexity})\")\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "816d9db1-01ff-41f4-9241-0dd12dd11118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.7086 | Val Accuracy = 0.8500\n",
      "Epoch 2: Train Loss = 0.6838 | Val Accuracy = 0.9500\n",
      "Epoch 3: Train Loss = 0.5151 | Val Accuracy = 1.0000\n",
      "Epoch 4: Train Loss = 0.4591 | Val Accuracy = 1.0000\n",
      "Epoch 5: Train Loss = 0.3303 | Val Accuracy = 0.9000\n",
      "Epoch 6: Train Loss = 0.2703 | Val Accuracy = 1.0000\n",
      "Epoch 7: Train Loss = 0.1862 | Val Accuracy = 1.0000\n",
      "Epoch 8: Train Loss = 0.1200 | Val Accuracy = 0.9500\n",
      "Epoch 9: Train Loss = 0.0955 | Val Accuracy = 0.9500\n",
      "Epoch 10: Train Loss = 0.0699 | Val Accuracy = 1.0000\n",
      "Epoch 11: Train Loss = 0.0507 | Val Accuracy = 1.0000\n",
      "Epoch 12: Train Loss = 0.0386 | Val Accuracy = 1.0000\n",
      "Epoch 13: Train Loss = 0.0338 | Val Accuracy = 1.0000\n",
      "Epoch 14: Train Loss = 0.0287 | Val Accuracy = 1.0000\n",
      "Epoch 15: Train Loss = 0.0249 | Val Accuracy = 1.0000\n",
      "Epoch 16: Train Loss = 0.0184 | Val Accuracy = 1.0000\n",
      "Epoch 17: Train Loss = 0.0170 | Val Accuracy = 1.0000\n",
      "Epoch 18: Train Loss = 0.0138 | Val Accuracy = 1.0000\n",
      "Epoch 19: Train Loss = 0.0117 | Val Accuracy = 1.0000\n",
      "Epoch 20: Train Loss = 0.0117 | Val Accuracy = 1.0000\n",
      "Epoch 21: Train Loss = 0.0097 | Val Accuracy = 1.0000\n",
      "Epoch 22: Train Loss = 0.0094 | Val Accuracy = 1.0000\n",
      "Epoch 23: Train Loss = 0.0092 | Val Accuracy = 1.0000\n",
      "Epoch 24: Train Loss = 0.0082 | Val Accuracy = 1.0000\n",
      "Epoch 25: Train Loss = 0.0076 | Val Accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "combined = list(zip(texts, labels))\n",
    "random.shuffle(combined)\n",
    "texts[:], labels[:] = zip(*combined)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, gpt2_model, gpt2_tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.gpt2_model = gpt2_model\n",
    "        self.gpt2_tokenizer = gpt2_tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        perplexity = compute_perplexity(text, self.gpt2_model, self.gpt2_tokenizer, device)\n",
    "\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].squeeze(0),\n",
    "            'attention_mask': enc['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "            'perplexity': torch.tensor(perplexity, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size + 1, 2)  # Add 1 to dimension for perplexity feature\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, perplexity):\n",
    "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = self.dropout(out.pooler_output)\n",
    "        \n",
    "        x = torch.cat((pooled, perplexity.unsqueeze(1)), dim=1)  # Add 1 to dimension for perplexity feature\n",
    "        return self.fc(x)\n",
    "\n",
    "def train_model(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        perplexity = batch['perplexity'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, perplexity)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            perplexity = batch['perplexity'].to(device)\n",
    "            outputs = model(input_ids, attention_mask, perplexity)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "train_ds = TextDataset(train_texts, train_labels, bert_tokenizer, gpt2_model, gpt2_tokenizer)\n",
    "val_ds = TextDataset(val_texts, val_labels, bert_tokenizer, gpt2_model, gpt2_tokenizer)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(25):\n",
    "    train_loss = train_model(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_acc = evaluate_model(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f} | Val Accuracy = {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "61a434ce-b56c-4efb-a740-caca7250f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, gpt2_model, gpt2_tokenizer, device, max_len=128):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    perplexity = compute_perplexity(text, gpt2_model, gpt2_tokenizer, device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, torch.tensor([perplexity], dtype=torch.float).to(device))\n",
    "        \n",
    "        predicted_label = torch.argmax(outputs, dim=1).item()\n",
    "    \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f97a902d-1529-4ae5-890a-c7c9c9988145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Human] Human\n",
      "[Human] Human\n",
      "[Human] Human\n",
      "[Human] Human\n",
      "[AI] Human\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n"
     ]
    }
   ],
   "source": [
    "with open('testarticles.json', 'r', encoding='utf-8') as f:\n",
    "    testarticles = json.load(f)\n",
    "\n",
    "test_texts = [test[\"text\"] for test in testarticles]\n",
    "\n",
    "truevalue = [\"Human\", \"Human\", \"Human\", \"Human\", \"Human\", \"AI\", \"AI\", \"AI\", \"AI\", \"AI\"]\n",
    "\n",
    "predicted_classes = []\n",
    "for text in test_texts:\n",
    "    pred = predict(text, model, bert_tokenizer, gpt2_model, gpt2_tokenizer, device)\n",
    "    predicted_classes.append(pred)\n",
    "i = 0\n",
    "for text, pred in zip(test_texts, predicted_classes):\n",
    "    label = \"AI\" if pred == 1 else \"Human\"\n",
    "    print(f\"[{label}] {truevalue[i]}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7eca1e41-0c08-4f81-85e9-b040f571dbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Perplexity: 35.8877\n",
      "AI Perplexity: 30.6813\n"
     ]
    }
   ],
   "source": [
    "htext, aitext = texts[:50], texts[50:]\n",
    "for text in htext:\n",
    "    perplexity += compute_perplexity(text, gpt2_model, gpt2_tokenizer, device)\n",
    "perplexity /= 50\n",
    "print(f\"Human Perplexity: {perplexity:.4f}\")\n",
    "for  text in aitext:\n",
    "    perplexity += compute_perplexity(text, gpt2_model, gpt2_tokenizer, device)\n",
    "perplexity /= 50\n",
    "print(f\"AI Perplexity: {perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9becd483-ae1c-4dd8-ad66-d68d858fb4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burstiness: 2.5373\n",
      "Burstiness: 2.3697\n"
     ]
    }
   ],
   "source": [
    "for text in htext:\n",
    "    burstiness_score += compute_burstiness(text, tokenizer)\n",
    "burstiness_score /= 50\n",
    "print(f\"Burstiness: {burstiness_score:.4f}\")\n",
    "for text in aitext:\n",
    "    burstiness_score += compute_burstiness(text, tokenizer)\n",
    "burstiness_score /= 50\n",
    "print(f\"Burstiness: {burstiness_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0c9d4aab-d05c-48ed-ac46-8328569e2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, gpt2_model, gpt2_tokenizer, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.gpt2_model = gpt2_model\n",
    "        self.gpt2_tokenizer = gpt2_tokenizer\n",
    "        self.perplexities = [compute_perplexity(t,gpt2_model, gpt2_tokenizer, device) for t in texts]\n",
    "        self.burstinesses = [compute_burstiness(t, gpt2_tokenizer) for t in texts]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        enc = self.tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=self.max_len,\n",
    "        return_tensors='pt'\n",
    "        )\n",
    "    \n",
    "        perplexity = compute_perplexity(text, self.gpt2_model, self.gpt2_tokenizer, device)\n",
    "        burstiness = compute_burstiness(text, self.tokenizer)\n",
    "\n",
    "        return {\n",
    "        'input_ids': enc['input_ids'].squeeze(0),\n",
    "        'attention_mask': enc['attention_mask'].squeeze(0),\n",
    "        'label': torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "        'perplexity': torch.tensor(perplexity, dtype=torch.float),\n",
    "        'burstiness': torch.tensor(burstiness, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2a2a7ad3-867c-4dcc-8fc4-01c7d230c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size + 2, 2) # Add 2 for perplexity and burstiness\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, perplexity, burstiness):\n",
    "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = self.dropout(out.pooler_output)\n",
    "\n",
    "        x = torch.cat((pooled, perplexity.unsqueeze(1), burstiness.unsqueeze(1)), dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f97243ac-e4a8-4ff3-9570-731e5afe8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        perplexity = batch['perplexity'].to(device)\n",
    "        burstiness = batch['burstiness'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, perplexity, burstiness)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "69159044-c8c2-4d8d-85c5-bca3f754408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            perplexity = batch['perplexity'].to(device)\n",
    "            burstiness = batch['burstiness'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, perplexity, burstiness)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "87578434-c682-483e-b9d6-1a8fe4b72a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.7404 | Val Accuracy = 0.7000\n",
      "Epoch 2: Train Loss = 0.6079 | Val Accuracy = 0.9000\n",
      "Epoch 3: Train Loss = 0.4837 | Val Accuracy = 1.0000\n",
      "Epoch 4: Train Loss = 0.3887 | Val Accuracy = 1.0000\n",
      "Epoch 5: Train Loss = 0.2805 | Val Accuracy = 1.0000\n",
      "Epoch 6: Train Loss = 0.1975 | Val Accuracy = 1.0000\n",
      "Epoch 7: Train Loss = 0.1411 | Val Accuracy = 1.0000\n",
      "Epoch 8: Train Loss = 0.0993 | Val Accuracy = 1.0000\n",
      "Epoch 9: Train Loss = 0.0713 | Val Accuracy = 1.0000\n",
      "Epoch 10: Train Loss = 0.0502 | Val Accuracy = 1.0000\n",
      "Epoch 11: Train Loss = 0.0389 | Val Accuracy = 1.0000\n",
      "Epoch 12: Train Loss = 0.0276 | Val Accuracy = 1.0000\n",
      "Epoch 13: Train Loss = 0.0241 | Val Accuracy = 1.0000\n",
      "Epoch 14: Train Loss = 0.0201 | Val Accuracy = 1.0000\n",
      "Epoch 15: Train Loss = 0.0159 | Val Accuracy = 1.0000\n",
      "Epoch 16: Train Loss = 0.0145 | Val Accuracy = 1.0000\n",
      "Epoch 17: Train Loss = 0.0107 | Val Accuracy = 1.0000\n",
      "Epoch 18: Train Loss = 0.0102 | Val Accuracy = 1.0000\n",
      "Epoch 19: Train Loss = 0.0083 | Val Accuracy = 1.0000\n",
      "Epoch 20: Train Loss = 0.0081 | Val Accuracy = 1.0000\n",
      "Epoch 21: Train Loss = 0.0072 | Val Accuracy = 1.0000\n",
      "Epoch 22: Train Loss = 0.0068 | Val Accuracy = 1.0000\n",
      "Epoch 23: Train Loss = 0.0063 | Val Accuracy = 1.0000\n",
      "Epoch 24: Train Loss = 0.0055 | Val Accuracy = 1.0000\n",
      "Epoch 25: Train Loss = 0.0054 | Val Accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "train_ds = TextDataset(train_texts, train_labels, bert_tokenizer, gpt2_model, gpt2_tokenizer, max_len=128)\n",
    "val_ds = TextDataset(val_texts, val_labels, bert_tokenizer, gpt2_model, gpt2_tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "model = BERTClassifier().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(25):\n",
    "    train_loss = train_model(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_acc = evaluate_model(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f} | Val Accuracy = {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1aaa479a-6526-4ae3-8391-7730b6230ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, gpt2_model, gpt2_tokenizer, device, max_len=128):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    perplexity = compute_perplexity(text, gpt2_model, gpt2_tokenizer, device)\n",
    "\n",
    "    burstiness = compute_burstiness(text, tokenizer)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        \n",
    "\n",
    "        outputs = model(input_ids, attention_mask, \n",
    "                         torch.tensor([perplexity], dtype=torch.float).to(device),\n",
    "                         torch.tensor([burstiness], dtype=torch.float).to(device))\n",
    "        \n",
    "\n",
    "        predicted_label = torch.argmax(outputs, dim=1).item()\n",
    "    \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "60fb6721-e537-4f98-b5d0-c4e45ce98e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Human] Human\n",
      "[AI] Human\n",
      "[Human] Human\n",
      "[AI] Human\n",
      "[AI] Human\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n",
      "[AI] AI\n"
     ]
    }
   ],
   "source": [
    "with open('testarticles.json', 'r', encoding='utf-8') as f:\n",
    "    testarticles = json.load(f)\n",
    "\n",
    "test_texts = [test[\"text\"] for test in testarticles]\n",
    "\n",
    "truevalue = [\"Human\", \"Human\", \"Human\", \"Human\", \"Human\", \"AI\", \"AI\", \"AI\", \"AI\", \"AI\"]\n",
    "\n",
    "predicted_classes = []\n",
    "for text in test_texts:\n",
    "    pred = predict(text, model, bert_tokenizer, gpt2_model, gpt2_tokenizer, device)\n",
    "    predicted_classes.append(pred)\n",
    "i = 0\n",
    "for text, pred in zip(test_texts, predicted_classes):\n",
    "    label = \"AI\" if pred == 1 else \"Human\"\n",
    "    print(f\"[{label}] {truevalue[i]}\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
